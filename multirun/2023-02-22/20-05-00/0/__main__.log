[2023-02-22 20:05:00,907][root][INFO] - Config: 
model:
  name: baseGNN
  n_classes: 2
  data_type: graph
  num_layers: 1
  layer_module: GCNConv
  hidden_dim: 32
  use_abs_weight: true
  use_weighted_edges: false
  final_node_dim: 32
  pooling: mean
  dropout: 0.2
  use_batchnorm: true
  num_heads: 2
  mlp_config:
    in_size: null
    out_size: null
    act_func: null
    act_func_params: null
    layers: []
seed: 1380
dataset:
  name: cobre
  data_type: graph
  experiment_type: fmri
  atlas: aal
  data_path: !!python/object/apply:pathlib.PosixPath
  - /
  - mnt
  - workspace
  - graph_NN
  - neurograph
  - datasets
  abs_thr: null
  pt_thr: null
  feature_type: conn_profile
train:
  device: cuda
  epochs: 20
  batch_size: 8
  valid_batch_size: 8
  optim: Adam
  optim_args:
    lr: 0.001
    weight_decay: 0.0001
  scheduler: null
  scheduler_metric: loss
  scheduler_args:
    factor: 0.1
    patience: 5
    verbose: true
  select_best_metric: loss
  loss: CrossEntropyLoss
  loss_args:
    reduction: sum
  prob_thr: 0.5
log:
  test_step: 1
  wandb_project: mri_gnn_2
  wandb_name: null
  wandb_mode: null

[2023-02-22 20:05:03,774][root][INFO] - Model architecture:
baseGNN(
  (convs): ModuleList(
    (0): Sequential(
      (0): GCNConv(116, 32)
      (1): LeakyReLU(negative_slope=0.2)
      (2): Dropout(p=0.2, inplace=False)
      (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (fcn): BasicMLP(
    (net): Sequential(
      (0): Sequential(
        (0): Linear(in_features=32, out_features=2, bias=True)
      )
    )
  )
))
[2023-02-22 20:05:03,775][root][INFO] - Run training on fold: 0
