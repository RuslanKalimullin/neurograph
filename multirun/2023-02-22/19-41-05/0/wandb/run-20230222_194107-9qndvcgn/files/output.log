[2023-02-22 19:41:08,121][root][INFO] - Model architecture:
baseGNN(
  (convs): ModuleList()
  (fcn): BasicMLP(
    (net): Sequential(
      (0): Sequential(
        (0): Linear(in_features=32, out_features=2, bias=True)
      )
    )
  )
))
[2023-02-22 19:41:08,122][root][INFO] - Run training on fold: 0
[2023-02-22 19:41:08,143][HYDRA] 	#1 : +model=baseGNN model.data_type=graph model.num_layers=2 model.hidden_dim=32 dataset.pt_thr=null train.epochs=20 train.scheduler=null
[2023-02-22 19:41:08,368][root][INFO] - Config:
model:
  name: baseGNN
  n_classes: 2
  data_type: graph
  num_layers: 2
  layer_module: GCNConv
  hidden_dim: 32
  use_abs_weight: true
  use_weighted_edges: false
  final_node_dim: 32
  pooling: mean
  dropout: 0.2
  use_batchnorm: true
  num_heads: 2
  mlp_config:
    in_size: null
    out_size: null
    act_func: null
    act_func_params: null
    layers: []
seed: 1380
dataset:
  name: cobre
  data_type: graph
  experiment_type: fmri
  atlas: aal
  data_path: !!python/object/apply:pathlib.PosixPath
  - /
  - mnt
  - workspace
  - graph_NN
  - neurograph
  - datasets
  abs_thr: null
  pt_thr: null
  feature_type: conn_profile
train:
  device: gpu
  epochs: 20
  batch_size: 8
  valid_batch_size: 8
  optim: Adam
  optim_args:
    lr: 0.001
    weight_decay: 0.0001
  scheduler: null
  scheduler_metric: loss
  scheduler_args:
    factor: 0.1
    patience: 5
    verbose: true
  select_best_metric: loss
  loss: CrossEntropyLoss
  loss_args:
    reduction: sum
  prob_thr: 0.5
log:
  test_step: 1
  wandb_project: mri_gnn_2
  wandb_name: null
  wandb_mode: null
Error executing job with overrides: ['+model=baseGNN', 'model.data_type=graph', 'model.num_layers=1', 'model.hidden_dim=32', 'dataset.pt_thr=null', 'train.epochs=20', 'train.scheduler=null']
Traceback (most recent call last):
  File "/mnt/workspace/graph_NN/neurograph/neurograph/train/__main__.py", line 63, in main
    metrics = train(ds, cfg)
  File "/mnt/workspace/graph_NN/neurograph/neurograph/train/train.py", line 60, in train
    valid_metrics, best_model = train_one_split(
  File "/mnt/workspace/graph_NN/neurograph/neurograph/train/train.py", line 140, in train_one_split
    data, y = handle_batch(data, device)
  File "/mnt/workspace/graph_NN/neurograph/neurograph/train/train.py", line 105, in handle_batch
    batch = batch.to(device)
  File "/usr/local/lib/python3.10/site-packages/torch_geometric/data/data.py", line 216, in to
    return self.apply(
  File "/usr/local/lib/python3.10/site-packages/torch_geometric/data/data.py", line 204, in apply
    store.apply(func, *args)
  File "/usr/local/lib/python3.10/site-packages/torch_geometric/data/storage.py", line 146, in apply
    self[key] = recursive_apply(value, func)
  File "/usr/local/lib/python3.10/site-packages/torch_geometric/data/storage.py", line 495, in recursive_apply
    return func(data)
  File "/usr/local/lib/python3.10/site-packages/torch_geometric/data/data.py", line 217, in <lambda>
    lambda x: x.to(device=device, non_blocking=non_blocking), *args)
RuntimeError: Expected one of cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, fpga, ort, xla, lazy, vulkan, mps, meta, hpu, privateuseone device type at start of device string: gpu
Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.